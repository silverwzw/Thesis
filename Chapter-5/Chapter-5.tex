\chapter{Performance}
\label{chap:perform}

    As an important resource management component in the operating system, the performance of a file system has a large influence on the operating system. In this chapter, we will evaluate the performance of the design. We will be focusing on the time efficiency of the file system and the space efficiency of the snapshot system.

\section{File System Benchmark}

    In this section, the performance of the Kabi File System is evaluated using the file system benchmark tool ``postmark''\cite{postmark}. All tests are using the default benchmark settings of postmark which include 500 stand-alone file creations, 264 file creations mixed with transactions, 243 file reads, 257 file appends and 764 file deletions.

    We compare our proof-of-concept implementation with other popular file systems. In our implementation, we use the FUSE-JNA (\url{http://fusejna.net/}) as the Java language binding for FUSE. FUSE-JNA is designed for fast development of concept file system whereas its performance is not very satisfied. FUSE-JNA creates Java thread for every file system call, uses JNA to communicate with the fuse library, and switch between kernel space and user space very frequently. Hence the overhead of using FUSE-JNA is significant. In order to eliminate such overhead in comparison, the file system performance is compared between Kabi File System and FUSE-JNA wrapped Ext4/NFS.

    Two sets of tests are performed: the local test set and the remote test set. In the local test set, Kabi File System client and the backend MongoDB are deployed on the same machine. The performance of Kabi File System is compared to a FUSE-JNA wrapped Ext4 file system. The testing environment is 64-bit Ubuntu 12.04LTS with one 2.4GHz 6MB cache Intel i7-2760QM CPU, in total 24GB DDR3 1333MHz RAM, and a 7200 rpm SATA hard disk. In the remote test set, Kabi File System client and the backend MongoDB are deployed on different machines. The remote test uses Amazon AWS service to build the testing environment. Both machines use Amazon EC2 t2.micro instance with one 8GB EBS volume and connect to a 10 Gbps local area network. The operating system is standard 64-bit Ubuntu image provided by Amazon AWS. The remote test compares Kabi File System with a FUSE-JNA wrapped NFS. 

    The file system test results are shown in \tref{tab:fs_performance}. The result shows that although as a local file system the Kabi File System is not as good as Ext4, but as a disitributed file system it is comparable to NFS.

\begin{lscape} 
\begin{table}
\caption{File System Performance Test}
\label{tab:fs_performance}
\begin{center}
\begin{threeparttable}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{Scenario} & \multicolumn{5}{c|}{Tests\tnote{1}} \\
\hline
File System & Test Set & Creation (stand-alone) & Creation (with transaction) & File Read & File Append & File Delete\\
\hline
Kabi & local & 83 & 33 & 30 & 32 & 47 \\
\hline
Ext4\tnote{2}& local & 96 & 49 & 53 & 46 & 88 \\
\hline
Kabi & remote & 55 & 29 & 27 & 28 & 36 \\
\hline
NFS \tnote{2,3} & remote & 45 & 26 & 24 & 25 & 36 \\
\hline
\end{tabular}
\begin{tablenotes}
\item[1] Test results are in ``operation per second'', the larger the better.
\item[2] The file system is wrapped with FUSE-JNA.
\item[3] The client uses NFS to mount a directory on remote Ext4 partition.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}
\end{lscape} 

\section {Efficiency of Snapshot and Deduplication}

    This section will focus on the space efficiency of the snapshot system. We are going to measure the space efficiency of the snapshot system by estimating the average space cost of a snapshot of a single file. We will study the influence of two factors against the space efficiency. The first factor is the ratio of file size against block size. The second factor is the proportion of ``truncated section'' in the file. A ``truncated section'' referes to those section that are not referring to a whole block. For example, the the thrid section in \fref{fig:rsync} or the second and thrid section in \fref{fig:file_and_section} are all truncated sections.

    We used the following steps to estimate the storage space occupied by a snapshot (all random numbers follows uniform distribution):

\begin{enumerate}

	\item Initialize the file system with block size $B$.

	\item Generate a file with size $F$.

	\item Fill the file with sections and let a certain proportion ($P$) of the sections be truncated.

	\item Take a snaphot of the file and make two side branches.
	
	\item Switch to side branch 1, insert random number of bytes into the file at random offset.

	\item Take a snapshot on side branch 1 and calculate the total space occupied by this snapshot.

	\item Switch to side branch 2, overwrite random number of bytes from random offset.

	\item Take a snapshot on side branch 2 and calculate the total space occupied by this snapshot.

	\item Repeat above steps for 10,000 times to get average value.

\end{enumerate}

    \tref{tab:sample_result} shows two sample results of such experiment. The first three columns in the table are the variables of the experiments. The later four columns are the data gathered from the experiments. For example, the column labeled ``overwrite, classic'' means corresponding write operation is an overwrite request and the algorithm used by snapshot system is classic copy-on-write.

    The first row in \tref{tab:sample_result} represents an experiment on a Kabi File System initialized with 128-byte block size. The target file is a 12,608-byte file where 3\% of all sections are truncated. The result shows that on average it takes a classic copy-on-write snapshot system 3,288 bytes to take a snapshot after an overwrite operation. It takes 103 bytes more for a Kabi File System to take a snapshot under the same condition. When it comes to insertion, on average it only takes the Kabi File System 3,256 bytes to take a snapshot after an insertion while it costs almost 2 times more space for a classic copy-on-write snapshot system to do so.

    This result is not difficult to explain. Because there is not much duplicated data in the overwrite scenario, SHA hashes and rolling checksums become overheads. This makes the performance of Kabi File System a little lower than the classic approach. But in the insertion scenario, lots of duplicated data can be found. The rsync algorithm is able to find the duplications to improve the efficiency. On the contrary, the classic approach cannot detect and make use of these duplicated data. So the Kabi File System have a better performance when it comes to insertion.
    
    The second row in \tref{tab:sample_result} represents another experiment different from the first one in file size. The file size in the second experiment equals to 126,080 bytes. It is obvious that when the file size becomes larger, the amount of space that is used to take a snapshot also become larger. Because of that, we cannot directly compare the amount of space occupied/saved in different snapshot - saving 10 bytes in a snapshot of a 100-Giga-byte file is obviously less efficient than saving 10 bytes in a snapshot of 100GB file. Therefore we introduce the normalized data as shown in \tref{tab:norm}. The major difference between \tref{tab:norm} and \tref{tab:sample_result} is that in \tref{tab:norm} we use the size of the file to normailze the result data so that we can compare results from different experiments easier.

\begin{lscape} 
\begin{table}
\caption{Sample result of the experiment}
\label{tab:sample_result}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{experiment variables} & \multicolumn{4}{c|}{write operation and algorithm used} \\
\hline
block size & file size & truncated section & overwrite, classic & overwrite, Kabi & insert, classic & insert, Kabi\\
\hline
128 & 12608 & 3\% & 3288 & 3391 & 9530 & 3256 \\
\hline
128 & 126080 & 3\% & 31722 & 32205 & 94867 & 32557 \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{Normalized data}
\label{tab:norm}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{experiment variables} & \multicolumn{4}{c|}{write operation and algorithm used} \\
\hline
block size & file size & truncated section & overwrite, classic & overwrite, Kabi & insert, classic & insert, Kabi\\
\hline
128 & 12608 & 3\% & 0.2607 & 0.2689 & 0.7558 & 0.2582 \\
\hline
128 & 126080 & 3\% & 0.2516 & 0.2554 & 0.7524 & 0.2582 \\
\hline
\end{tabular}
\end{center}
\end{table}
\end{lscape}

\subsection{Block Size and File Size}

    The block size and the file size also influence the efficiency of a snapshot system. A high file-size-to-block-size ratio usually means fine-grained blocks. A classic copy-on-write snapshot will get better efficiency if it is a fine-grained target file. Consider the extreme case where the file-size-to-block-size ratio is 1. Then the file contains exactly one block. Therefore any change means a complete rewrite to the file by classic copy-on-write strategy. Column 4 and 6 in \tref{tab:fb_ratio} reflects this influence where high file-size-to-block-size ratio improves the efficiency of classic copy-on-write system.

    However, column 7 shows that there is no obvious relationship between file-size-to-block-size ratio and efficiency when doing an insertion in Kabi File System. One reason for this could be the Kabi File System can truncate block into smaller sections freely as shown in \fref{fig:buffer}. Therefore the Kabi File System can have fine-grained sections even though the file system uses a large block size.
    
    The data in column 5 reflects the fact that an increase in file-size-to-block-size ratio will result in an improvement in efficiency. The reason could be that the proportion of the metadata will reduces as the file size increases. For example, an overwrite operation can result in at most two additional sections added to the file node. This is an extra 56-byte metadata overhead. Compared to a 704-byte file, such overhead is large. On the other hand, if the file size is 14,008 bytes, this overhead can be omitted.

\begin{lscape} 
\begin{table}
\caption{File Size to Block Size ratio}
\label{tab:fb_ratio}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{experiment variables} & \multicolumn{4}{c|}{write operation and algorithm used} \\
\hline
block size & file size & truncated section & overwrite, classic & overwrite, Kabi & insert, classic & insert, Kabi\\
\hline
128 & 704 & 17\% & 0.4531 & 0.5127 & 0.8338 & 0.2983 \\
\hline
128 & 1408 & 17\% & 0.3514 & 0.3934 & 0.7933 & 0.2962 \\
\hline
128 & 2112 & 17\% & 0.3129 & 0.3532 & 0.7789 & 0.2964 \\
\hline
128 & 3520 & 17\% & 0.2884 & 0.3213 & 0.7702 & 0.2972 \\
\hline
128 & 7040 & 17\% & 0.2681 & 0.2949 & 0.7589 & 0.2955 \\
\hline
128 & 14008 & 17\% & 0.2593 & 0.2828 & 0.7545 & 0.2957 \\
\hline
\end{tabular}
\end{center}
\end{table}
\end{lscape}

\subsection{Truncate Ratio}

    The rsync algorithm searches duplication in local buffer and remote sections. It uses the rolling checksum of sections to find duplications. But a truncated section does not have a valid rolling checksum thus it cannot be benefited from the rsync algorithm. Hence we can infer that the more truncated sections we have, the less efficient snapshot system and file system deduplication will be.

    \tref{tab:truncate_ratio} supports this inference. It shows the relationship between the efficiency and truncated sections. Because a classic copy-on-write snapshot system does not have ``truncated section'', they are not influenced by this experiment variable. On the other hand, truncated sections significantly influence the efficiency of Kabi File System. It makes rsync algorithm less powerful. It also reduces the chance to find two duplicated block using the deduplicate function offered by the file system. When all sections are truncated, the rsync algorithm no longer provide any extra efficiency in insert operation.

    In this experiment, we explicitly set the size of truncated section to be half of the block size. That means for a Kabi File System with a 128-byte block size, the overhead (28 bytes) in metadata is almost half of the data contains in truncated section. In other words, for every 2 bytes stored in truncated section, there is 1 extra byte cost in metadata. Since the increase in truncated-to-untruncated ratio implies more truncated section which is less efficient, this explains the significant decrease in efficiency in column 5 of \tref{tab:truncate_ratio}.

\begin{lscape} 
\begin{table}
\caption{Truncate Ratio}
\label{tab:truncate_ratio}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{experiment variables} & \multicolumn{4}{c|}{write operation and algorithm used} \\
\hline
block size & file size & truncated section & overwrite, classic & overwrite, Kabi & insert, classic & insert, Kabi\\
\hline
128 & 12800 & 0\% & 0.2596 & 0.2645 & 0.7547 & 0.2495 \\
\hline
128 & 12800 & 10\% & 0.2600 & 0.2752 & 0.7558 & 0.2750 \\
\hline
128 & 12800 & 18\% & 0.2599 & 0.2856 & 0.7557 & 0.3002 \\
\hline
128 & 12800 & 33\% & 0.2606 & 0.3071 & 0.7569 & 0.3513 \\
\hline
128 & 12800 & 46\% & 0.2616 & 0.3290 & 0.7579 & 0.4026 \\
\hline
128 & 12800 & 57\% & 0.2616 & 0.3500 & 0.7583 & 0.4532 \\
\hline
128 & 12800 & 71\% & 0.2596 & 0.3792 & 0.7530 & 0.5252 \\
\hline
128 & 12800 & 82\% & 0.2579 & 0.4089 & 0.7505 & 0.5980 \\
\hline
128 & 12800 & 91\% & 0.2593 & 0.4417 & 0.7536 & 0.6758 \\
\hline
128 & 12800 & 100\% & 0.2601 & 0.4737 & 0.7561 & 0.7536 \\
\hline
\end{tabular}
\end{center}
\end{table}
\end{lscape}

\section{Conclusion}

    In this Chapter, we showed the effects of three important factors that affect the snapshot efficiency. The three factors are the block size, the file-size-to-block-size ratio and the proportion of truncated sections.

    Generally, in Kabi snapshot system an increase in block size or an increase in file-size-to-block-size ratio will make the overheads of metadata more efficient. The proportion of truncated sections is the most important factor among the three factors. An increase in this proportion will significantly decrease the efficiency of the snapshot system in Kabi File System.
